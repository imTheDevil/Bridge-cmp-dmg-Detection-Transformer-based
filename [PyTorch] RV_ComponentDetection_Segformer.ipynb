{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imTheDevil/Bridge-cmp-dmg-Detection-Transformer-based/blob/main/%5BPyTorch%5D%20RV_ComponentDetection_Segformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRhHFhMOVP3v"
      },
      "source": [
        "### **Component Detection Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOWm2-h3uCsr"
      },
      "source": [
        "##**References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z44Dg5wNgeh7"
      },
      "source": [
        "**Official Source Code for modeling PyTorch based SegFormer: https://github.com/NVlabs/SegFormer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIRC9Q5YdikD"
      },
      "source": [
        "**Example notebooks for PyTorch SegFormer: https://colab.research.google.com/drive/1_t3KvF3qg4IJfEhTuftFI1GSlscapNgf?usp=sharing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR3M-3Z0d-cj"
      },
      "source": [
        "**Blog Post on traning SegFormer using custom dataset: https://blog.roboflow.com/how-to-train-segformer-on-a-custom-dataset-with-pytorch-lightning/**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiJwiK2Chrb5"
      },
      "source": [
        "**Cross Entropy Loss Error - https://discuss.pytorch.org/t/cross-entropy-loss-error-on-image-segmentation/60194/12**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeFQEtxCg22l"
      },
      "source": [
        "##**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7xJrOO-eIZH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMx52KmvIHs-"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01620e17"
      },
      "outputs": [],
      "source": [
        "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation, SegformerImageProcessor\n",
        "from datasets import load_metric\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ9rxHzf-GMh"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "print(\"Python version:\", platform.python_version())\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4WStqp8mCtm"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Set up the logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Specify the log file path\n",
        "log_file = \"/content/drive/MyDrive/PyTorch segformer/rerun/component/log_file_wtceloss.log\"  # Replace with your desired log file path\n",
        "\n",
        "# Create a file handler to write log records to the log file in 'append' mode\n",
        "file_handler = logging.FileHandler(log_file, mode='a')\n",
        "\n",
        "# Create a formatter for the log records\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# Add the file handler to the logger\n",
        "logger.addHandler(file_handler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUaQDpbD-lsX"
      },
      "outputs": [],
      "source": [
        "path_ds = os.path.join('/content/drive/MyDrive','Tokaido Dataset Full') #path to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4krZDY4r_iXh"
      },
      "outputs": [],
      "source": [
        "json_filepath = os.path.join(path_ds, \"id2label.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X7Kk2Lb-ufv"
      },
      "outputs": [],
      "source": [
        "#Function to change the path format\n",
        "def path_correct(path):\n",
        "  path = '/'.join(path[2:].split('\\\\'))\n",
        "  path = os.path.join(path_ds, path)\n",
        "  return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo8Jc2B5-SvH"
      },
      "outputs": [],
      "source": [
        "#Loading the training data for component images\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name',\n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftrain = pd.read_csv(os.path.join(path_ds,'files_train.csv'),names = col_names,delimiter=',')\n",
        "ftrain.iloc[:,0] = ftrain.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,1] = ftrain.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,2] = ftrain.iloc[:,2].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,3] = ftrain.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "train_comp = ftrain.loc[ftrain['regular images']==True, ['image file name', 'component label file name']]\n",
        "# train_dmg = ftrain.loc[ftrain['images containing damage in the RRDR']==True, ['image file name', 'damage label file name']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfOimpau-wSY"
      },
      "outputs": [],
      "source": [
        "train_comp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA1VMKHcwySb"
      },
      "outputs": [],
      "source": [
        "#Loading the testing data for component images\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name',\n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftest = pd.read_csv(os.path.join(path_ds,'files_test.csv'),names = col_names,delimiter=',')\n",
        "ftest.iloc[:,0] = ftest.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,1] = ftest.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,2] = ftest.iloc[:,2].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,3] = ftest.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "test_comp = ftest.loc[ftest['regular images']==True, ['image file name', 'component label file name']]\n",
        "# test_dmg = ftest.loc[ftest['images containing damage in the RRDR']==True, ['image file name', 'damage label file name']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qs6b7bsxR8W"
      },
      "outputs": [],
      "source": [
        "test_comp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs1LF0JIMDju"
      },
      "outputs": [],
      "source": [
        "train_comp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp05qt7AMGEs"
      },
      "outputs": [],
      "source": [
        "test_comp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMNG0xlAxXVN"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "shuffled_train_comp = train_comp.sample(frac=1)\n",
        "validation_proportion = 0.1\n",
        "num_validation_samples = int(len(shuffled_train_comp) * validation_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB7s6Hek_ygv"
      },
      "outputs": [],
      "source": [
        "# using validation data as 10% of whole training data\n",
        "train = shuffled_train_comp.iloc[num_validation_samples:]\n",
        "val = shuffled_train_comp.iloc[:num_validation_samples]\n",
        "test = test_comp[:1073]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26818f87"
      },
      "outputs": [],
      "source": [
        "class SemanticSegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, feature_extractor, dataframe):   #dataframe: dataset of paths of images and corresponding labels\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "        data = json.load(open(os.path.join(self.root_dir, 'id2label.json'), \"r\"))\n",
        "        self.id2label = {int(k): v for k, v in data.items()}\n",
        "\n",
        "        self.images = list(self.dataframe['image file name'])\n",
        "        self.masks = list(self.dataframe['component label file name'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = Image.open(self.images[idx])\n",
        "        segmentation_map = Image.open(self.masks[idx])\n",
        "\n",
        "        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\") # randomly crop + pad both image and segmentation map to same size\n",
        "\n",
        "        for k,v in encoded_inputs.items():\n",
        "          encoded_inputs[k].squeeze_() # removes \"batch\" dimension\n",
        "\n",
        "        return encoded_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMR7-WhigV2c"
      },
      "outputs": [],
      "source": [
        "feature_extractor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "feature_extractor.do_reduce_labels = False\n",
        "feature_extractor.size = 216"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b03e8794"
      },
      "outputs": [],
      "source": [
        "train_dataset = SemanticSegmentationDataset(path_ds, feature_extractor, train)\n",
        "val_dataset = SemanticSegmentationDataset(path_ds, feature_extractor, val)\n",
        "test_dataset = SemanticSegmentationDataset(path_ds, feature_extractor, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_sVDJd4EHAW"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "num_workers = 2\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmTs9ybNELkZ"
      },
      "outputs": [],
      "source": [
        "data = json.load(open(os.path.join(path_ds, 'id2label.json'), \"r\"))\n",
        "id2label = {int(k): v for k, v in data.items()}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZFylra8EHfg"
      },
      "outputs": [],
      "source": [
        "#no. of classes\n",
        "n_classes = len(id2label.keys())\n",
        "print(n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeYH5aMQF8Bk"
      },
      "outputs": [],
      "source": [
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    \"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
        "    return_dict=False,\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r9wqqUnGniM"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-8)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(\"Model Initialized!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5PWg5W9Yesh"
      },
      "outputs": [],
      "source": [
        "SMOOTH = 1e-6\n",
        "\n",
        "def iou_metric(outputs: torch.Tensor, labels: torch.Tensor):\n",
        "    # outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
        "    B, H, W = outputs.shape[0], outputs.shape[1], outputs.shape[2]\n",
        "    mask = (labels!=0) # we don't include the background class (class_id = 0 if any) in the calculation\n",
        "    outputs = outputs[mask]\n",
        "    labels = labels[mask]\n",
        "    outputs = outputs.view(B, H, W)#reshapes outputs and labels above to (B, H, W)\n",
        "    labels = labels.view(B, H, W)\n",
        "\n",
        "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "    union = (outputs | labels).float().sum((1, 2))         # Will be zero if both are 0\n",
        "\n",
        "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
        "\n",
        "    result = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10\n",
        "\n",
        "    return result.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zevuAaXJBKsJ"
      },
      "outputs": [],
      "source": [
        "class_weights = [0,\n",
        "                 1.8603616743670042,\n",
        "                 7.777137720077815,\n",
        "                 8.101747530670247,\n",
        "                 5.774730984703028,\n",
        "                 34.734403078289915,\n",
        "                 149.82883160257342,\n",
        "                 548.8487701219344,\n",
        "                 283754.9132947977] #These calculation code is shown at the end of notebook\n",
        "\n",
        "sum_weights = sum(class_weights)\n",
        "normalized_weights = [w/sum_weights for w in class_weights]\n",
        "weights_tensor = torch.tensor(class_weights) #converting normalized weights to pytorch tensor\n",
        "\n",
        "print(normalized_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ogy8AMiEPg3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def dice_loss(pred, target, smooth=1.0):\n",
        "    \"\"\"\n",
        "    Computes the Dice loss between predicted and target segmentation masks.\n",
        "\n",
        "    Args:\n",
        "        pred: Tensor of shape (batch_size, num_classes, height, width). The predicted segmentation masks.\n",
        "        target: Tensor of shape (batch_size, height, width). The ground truth segmentation masks.\n",
        "        smooth: Smoothing parameter to avoid division by zero.\n",
        "\n",
        "    Returns:\n",
        "        The Dice loss value as a scalar tensor.\n",
        "    \"\"\"\n",
        "    batch_size, num_classes, height, width = pred.size()\n",
        "\n",
        "    # Convert integer labels to one-hot encoding\n",
        "    target = F.one_hot(target, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "    # Compute softmax probabilities\n",
        "    pred = torch.softmax(pred, dim=1)\n",
        "\n",
        "    # Compute intersection and union\n",
        "    intersection = torch.sum(pred * target, dim=(2, 3))\n",
        "    union = torch.sum(pred, dim=(2, 3)) + torch.sum(target, dim=(2, 3))\n",
        "\n",
        "    # Compute Dice coefficient and loss\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "    loss = 1.0 - dice.mean()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz_ksW1TRqQI"
      },
      "outputs": [],
      "source": [
        "#initializing cross-entropy loss\n",
        "crit =torch.nn.functional.cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og0ndtihm3Jw"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/PyTorch segformer/rerun/component/comprerun_builtin.pt\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0_-UQXfKZOF"
      },
      "outputs": [],
      "source": [
        "t_loss={}\n",
        "v_loss={}\n",
        "t_acc={}\n",
        "v_acc={}\n",
        "m_iou={}\n",
        "pc_iou={}\n",
        "pixel_acc={}\n",
        "t_precision = {}\n",
        "v_precision = {}\n",
        "t_recall = {}\n",
        "v_recall = {}\n",
        "num_classes = 9 #including background class_id = 0\n",
        "\n",
        "for epoch in range(43, 46):  # loop over the dataset multiple times\n",
        "    print(\"Epoch:\", epoch)\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "    mean_iou = []\n",
        "    per_class_iou = [0] * num_classes\n",
        "    pixel_accuracy = 0\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        # get inputs\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "        # upsample\n",
        "        upsampled_logits = nn.functional.interpolate(outputs[1], size=labels.shape[-2:], mode=\"bilinear\")\n",
        "        predicted = upsampled_logits.argmax(dim=1)#for accuracy and iou calculations below\n",
        "\n",
        "        #accuracy\n",
        "        mask = (labels != 0) # we don't include the background class (class_id = 0 if any) in the accuracy calculation\n",
        "        pred_labels = predicted[mask].detach().cpu().numpy() #to numpy\n",
        "        true_labels = labels[mask].detach().cpu().numpy() #to numpy\n",
        "        accuracy = accuracy_score(pred_labels, true_labels)\n",
        "\n",
        "        # loss = dice_loss(upsampled_logits,labels)\n",
        "        loss = crit(upsampled_logits,labels, weight = weights_tensor.to(device))\n",
        "        # loss = outputs[0]\n",
        "\n",
        "        accuracies.append(accuracy)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    if(1):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for idx, batch in enumerate(val_dataloader):\n",
        "\n",
        "                #get inputs\n",
        "                pixel_values = batch[\"pixel_values\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                #forward\n",
        "                outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "                #upsample\n",
        "                upsampled_logits = nn.functional.interpolate(outputs[1], size=labels.shape[-2:], mode=\"bilinear\")\n",
        "                predicted = upsampled_logits.argmax(dim=1)#for accuracy calculation below\n",
        "\n",
        "                #accuracy\n",
        "                mask = (labels != 0) # we don't include the background class (class_id = 0 if any) in the accuracy calculation\n",
        "                pred_labels = predicted[mask].detach().cpu().numpy()\n",
        "                true_labels = labels[mask].detach().cpu().numpy()\n",
        "                accuracy = accuracy_score(pred_labels, true_labels)\n",
        "\n",
        "                # loss2 = dice_loss(upsampled_logits,labels)\n",
        "                loss2 = crit(upsampled_logits,labels, weight = weights_tensor.to(device))\n",
        "                # loss2 = outputs[0]\n",
        "\n",
        "                val_accuracies.append(accuracy)\n",
        "                val_losses.append(loss2.item())\n",
        "\n",
        "                #calculating mean iou\n",
        "                iou = iou_metric(predicted, labels)\n",
        "                mean_iou.append(iou.item())\n",
        "\n",
        "                # Calculating per-class IoU\n",
        "                for class_id in range(num_classes):\n",
        "                    true_class = (labels == class_id)\n",
        "                    pred_class = (predicted == class_id)\n",
        "                    intersection = torch.logical_and(true_class, pred_class).sum().item()\n",
        "                    union = torch.logical_or(true_class, pred_class).sum().item()\n",
        "                    piou = intersection / (union + 1e-6)  #small epsilon to avoid division by zero\n",
        "                    per_class_iou[class_id] += piou\n",
        "\n",
        "                # Calculating pixel-wise accuracy\n",
        "                correct_pixels = (predicted == labels).sum().item()\n",
        "                total_pixels = labels.nelement()\n",
        "                pixel_accuracy += correct_pixels / total_pixels\n",
        "\n",
        "                # Calculating Precision and recall\n",
        "                precision = precision_score(labels.flatten(), predicted.flatten(), average='weighted', zero_division=1)\n",
        "                recall = recall_score(labels.flatten(), predicted.flatten(), average='weighted', zero_division=1)\n",
        "\n",
        "                precision_scores.append(precision)\n",
        "                recall_scores.append(recall)\n",
        "\n",
        "    train_loss= np.mean(losses)\n",
        "    t_loss[epoch]=train_loss\n",
        "    val_loss = np.mean(val_losses)\n",
        "    v_loss[epoch]=val_loss\n",
        "    train_acc = sum(accuracies)/len(accuracies)\n",
        "    t_acc[epoch]=train_acc\n",
        "    val_acc = sum(val_accuracies)/len(val_accuracies)\n",
        "    v_acc[epoch]=val_acc\n",
        "    iou_score = np.mean(mean_iou)\n",
        "    m_iou[epoch]=iou_score\n",
        "\n",
        "    # Calculate average precision and recall for the epoch\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    v_precision[epoch] = avg_precision\n",
        "    v_recall[epoch] = avg_recall\n",
        "\n",
        "    # Average per-class IoU and pixel-wise accuracy over all batches\n",
        "    per_class_iou = [iou / len(val_dataloader) for iou in per_class_iou]\n",
        "    pc_iou[epoch]=per_class_iou\n",
        "    pixel_accuracy /= len(val_dataloader)\n",
        "    pixel_acc[epoch]=pixel_accuracy\n",
        "\n",
        "\n",
        "\n",
        "    state = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'train_acc':train_acc,\n",
        "            'val_acc':val_acc,\n",
        "            'mean_iou':iou_score,\n",
        "            'mean class iou': per_class_iou,\n",
        "            'pixel acc': pixel_accuracy,\n",
        "            'v_precision': avg_precision,\n",
        "            'v_recall': avg_recall\n",
        "            }\n",
        "\n",
        "    torch.save( state, \"/content/drive/MyDrive/PyTorch segformer/rerun/component/comprerun_wtce.pt\")\n",
        "\n",
        "    logger.info(f\"Epoch: {epoch}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    logger.info(f\"Epoch: {epoch}, Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}, Mean IoU: {iou_score:.4f}, per class iou: {per_class_iou}, pixel accuracy: {pixel_accuracy}, val precision: {avg_precision:.4f}, val recall: {avg_recall:.4f}\")\n",
        "\n",
        "    print(f\"Train accuracy: {train_acc}\\\n",
        "         Train Loss: {train_loss}\\\n",
        "         Val accuracy: {val_acc}\\\n",
        "         Val Loss: {val_loss}\\\n",
        "         Mean IOU: {iou_score}\\\n",
        "         mean class iou: {per_class_iou}\\\n",
        "         pixel acc: {pixel_accuracy}\\\n",
        "         val precision: {avg_precision}\\\n",
        "         val recall: {avg_recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists to store metrics for the testing phase\n",
        "num_classes = 9\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "test_mean_iou = []\n",
        "test_per_class_iou = [0] * num_classes\n",
        "test_pixel_accuracy = 0\n",
        "test_precision_scores = []\n",
        "test_recall_scores = []\n",
        "\n",
        "\n",
        "# Loop over the testing dataset\n",
        "with torch.no_grad():\n",
        "    for idx, batch in enumerate(tqdm(test_dataloader)):\n",
        "\n",
        "        # Get inputs\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "        # Upsample\n",
        "        upsampled_logits = nn.functional.interpolate(outputs[1], size=labels.shape[-2:], mode=\"bilinear\")\n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "\n",
        "        # Accuracy\n",
        "        mask = (labels != 0)\n",
        "        pred_labels = predicted[mask].detach().cpu().numpy()\n",
        "        true_labels = labels[mask].detach().cpu().numpy()\n",
        "        accuracy = accuracy_score(pred_labels, true_labels)\n",
        "\n",
        "        # Loss\n",
        "        # loss = crit(upsampled_logits, labels, weight=weights_tensor.to(device))\n",
        "        loss = outputs[0]\n",
        "\n",
        "        test_accuracies.append(accuracy)\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "        # Calculating mean IoU\n",
        "        iou = iou_metric(predicted, labels)\n",
        "        test_mean_iou.append(iou.item())\n",
        "\n",
        "        # Calculating per-class IoU\n",
        "        for class_id in range(num_classes):\n",
        "            true_class = (labels == class_id)\n",
        "            pred_class = (predicted == class_id)\n",
        "            intersection = torch.logical_and(true_class, pred_class).sum().item()\n",
        "            union = torch.logical_or(true_class, pred_class).sum().item()\n",
        "            piou = intersection / (union + 1e-6)\n",
        "            test_per_class_iou[class_id] += piou\n",
        "\n",
        "        # Calculating pixel-wise accuracy\n",
        "        correct_pixels = (predicted == labels).sum().item()\n",
        "        total_pixels = labels.nelement()\n",
        "        test_pixel_accuracy += correct_pixels / total_pixels\n",
        "\n",
        "        # Calculating Precision and Recall\n",
        "        precision = precision_score(labels.flatten(), predicted.flatten(), average='weighted', zero_division=1)\n",
        "        recall = recall_score(labels.flatten(), predicted.flatten(), average='weighted', zero_division=1)\n",
        "        test_precision_scores.append(precision)\n",
        "        test_recall_scores.append(recall)\n",
        "\n",
        "# Calculate average metrics for the testing phase\n",
        "test_loss = np.mean(test_losses)\n",
        "test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
        "test_mean_iou_score = np.mean(test_mean_iou)\n",
        "\n",
        "# Calculate average per-class IoU and pixel-wise accuracy over all batches\n",
        "test_per_class_iou = [iou / len(test_dataloader) for iou in test_per_class_iou]\n",
        "test_pixel_accuracy /= len(test_dataloader)\n",
        "\n",
        "# Calculate average precision and recall for the testing phase\n",
        "test_avg_precision = np.mean(test_precision_scores)\n",
        "test_avg_recall = np.mean(test_recall_scores)\n",
        "\n",
        "# Print and log the testing metrics\n",
        "logger.info(f\"Testing Loss: {test_loss:.4f}, Testing Acc: {test_accuracy:.4f}\")\n",
        "logger.info(f\"Testing Mean IoU: {test_mean_iou_score:.4f}, Testing per class IoU: {test_per_class_iou}\")\n",
        "logger.info(f\"Testing Pixel Accuracy: {test_pixel_accuracy:.4f}, Testing Precision: {test_avg_precision:.4f}, Testing Recall: {test_avg_recall:.4f}\")\n",
        "\n",
        "print(f\"Testing accuracy: {test_accuracy}\\\n",
        "     Testing Loss: {test_loss}\\\n",
        "     Testing Mean IOU: {test_mean_iou_score}\\\n",
        "     Testing per class iou: {test_per_class_iou}\\\n",
        "     Testing pixel acc: {test_pixel_accuracy}\\\n",
        "     Testing precision: {test_avg_precision}\\\n",
        "     Testing recall: {test_avg_recall}\")\n"
      ],
      "metadata": {
        "id": "5szE2P6HIYYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le1zi29u6IKh"
      },
      "outputs": [],
      "source": [
        "logger.info(f\"Epoch: {31}, Train Loss: {0.4349:.4f}, Train Acc: {0.8464:.4f}\")\n",
        "logger.info(f\"Epoch: {31}, Validation Loss: {0.5072:.4f}, Validation Acc: {0.8606:.4f}, Mean IoU: {0.6922:.4f}, per class iou: {[0.0, 0.8765833756333385, 0.49712489417880407, 0.5355120226074326, 0.7473910081556423, 0.3975825755813958, 0.08724355326916003, 0.03485675912864679, 0.0002494959546916023]}, pixel accuracy: {0.8606357957006716}, val precision: {0.8909:.4f}, val recall: {0.8606:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzvOW2l3OIvQ"
      },
      "outputs": [],
      "source": [
        "logger.info(f\"Epoch: {30}, Train Loss: {0.4618:.4f}, Train Acc: {0.8366:.4f}\")\n",
        "logger.info(f\"Epoch: {30}, Validation Loss: {0.7849:.4f}, Validation Acc: {0.7615:.4f}, Mean IoU: {0.5022:.4f}, per class iou: {[0.0, 0.7665766758423768, 0.45672861281235194, 0.38654116769852254, 0.7063124599659741, 0.2157116853566847, 0.075654487920314, 0.02852559773892011, 0.0001952106372549701]}, pixel accuracy: {0.761522436331312}, val precision: {0.8647:.4f}, val recall: {0.7615:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ2u4FcsoTOO"
      },
      "outputs": [],
      "source": [
        "#to get logs from previous sessions\n",
        "log_file = \"/content/drive/MyDrive/PyTorch segformer/rerun/component/log_file_wtceloss.log\"  # Replace with the path to your log file\n",
        "\n",
        "try:\n",
        "    with open(log_file, 'r') as file:\n",
        "        log_contents = file.read()\n",
        "        print(log_contents)\n",
        "except FileNotFoundError:\n",
        "    print(\"Log file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFfQ16Il6j0c"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/PyTorch segformer/rerun/component/comprerun_builtin.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "iou = checkpoint['mean_iou']\n",
        "v_loss = checkpoint['val_loss']\n",
        "t_acc = checkpoint['train_acc']\n",
        "v_acc = checkpoint['val_acc']\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ8GNqk5bYQq"
      },
      "outputs": [],
      "source": [
        "print('Metrics @ {}epoch-7000train-575val-{}loss are as follows:\\n'.format(epoch, 'builtince'))\n",
        "print('IOU = {}%'.format(iou*100))\n",
        "print('Train Loss = {}'.format(loss))\n",
        "print('Val Loss = {}'.format(v_loss))\n",
        "print('Train Accuracy = {}'.format(t_acc))\n",
        "print('Val Accuracy = {}'.format(v_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWaYlKBAc9vZ"
      },
      "outputs": [],
      "source": [
        "batchnum = 168\n",
        "i = 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    i = i + 1\n",
        "    images, masks = batch['pixel_values'].to(device), batch['labels'].to(device)\n",
        "    outputs = model(pixel_values=images, labels=masks)\n",
        "\n",
        "    logits = outputs[1]\n",
        "\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        logits,\n",
        "        size=masks.shape[-2:],\n",
        "        mode=\"bilinear\"\n",
        "    )\n",
        "\n",
        "    # loss = crit(upsampled_logits, masks, weight=weights_tensor.to(device))\n",
        "    loss = outputs[0]\n",
        "\n",
        "    predicted_mask = upsampled_logits.argmax(dim=1).detach().cpu().numpy()\n",
        "    masks = masks.detach().cpu().numpy()\n",
        "    original_images = images.detach().cpu().numpy()  # Retrieve original images\n",
        "\n",
        "    if i == batchnum:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color_map = {\n",
        "    0:(0,0,0),\n",
        "    1:(255,255,255),\n",
        "    2:(255,0,0),\n",
        "    3:(0,0,255),\n",
        "    4:(255,255,0),\n",
        "    5:(0,0,0),\n",
        "    6:(255,40,140),\n",
        "    7:(218,118,27),\n",
        "    8:(75,75,75)\n",
        "}"
      ],
      "metadata": {
        "id": "Y1PJAxRNKvwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nf2MHbw9AXU"
      },
      "outputs": [],
      "source": [
        "def prediction_to_vis(prediction):\n",
        "    vis_shape = prediction.shape + (3,)\n",
        "    vis = np.zeros(vis_shape)\n",
        "    for i,c in color_map.items():\n",
        "        vis[prediction == i] = color_map[i]\n",
        "    return Image.fromarray(vis.astype(np.uint8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vzIHanwJdAT"
      },
      "source": [
        "##**calculating weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QidXZriRJPh4"
      },
      "outputs": [],
      "source": [
        "#calculating weights of each class\n",
        "\n",
        "masks = train['component label file name'].to_numpy()\n",
        "\n",
        "import skimage.io\n",
        "p_of_class_0_pix=0\n",
        "p_of_class_1_pix=0\n",
        "p_of_class_2_pix=0\n",
        "p_of_class_3_pix=0\n",
        "p_of_class_4_pix=0\n",
        "p_of_class_5_pix=0\n",
        "p_of_class_6_pix=0\n",
        "p_of_class_7_pix=0\n",
        "p_of_class_8_pix=0\n",
        "for i in range(len(masks)):\n",
        "  img = skimage.io.imread(masks[i])\n",
        "\n",
        "  # counting the number of pixels\n",
        "  p_of_class_0_pix = p_of_class_0_pix+((np.sum(img == 0)/(360*640)))\n",
        "  p_of_class_1_pix = p_of_class_1_pix+((np.sum(img == 1)/(360*640)))\n",
        "  p_of_class_2_pix = p_of_class_2_pix+((np.sum(img == 2)/(360*640)))\n",
        "  p_of_class_3_pix = p_of_class_3_pix+((np.sum(img == 3)/(360*640)))\n",
        "  p_of_class_4_pix = p_of_class_4_pix+((np.sum(img == 4)/(360*640)))\n",
        "  p_of_class_5_pix = p_of_class_5_pix+((np.sum(img == 5)/(360*640)))\n",
        "  p_of_class_6_pix = p_of_class_6_pix+((np.sum(img == 6)/(360*640)))\n",
        "  p_of_class_7_pix = p_of_class_7_pix+((np.sum(img == 7)/(360*640)))\n",
        "  p_of_class_8_pix = p_of_class_8_pix+((np.sum(img == 8)/(360*640)))\n",
        "\n",
        "p_of_class_0_pix=p_of_class_0_pix/75.75\n",
        "p_of_class_1_pix=p_of_class_1_pix/75.75\n",
        "p_of_class_2_pix=p_of_class_2_pix/75.75\n",
        "p_of_class_3_pix=p_of_class_3_pix/75.75\n",
        "p_of_class_4_pix=p_of_class_4_pix/75.75\n",
        "p_of_class_5_pix=p_of_class_5_pix/75.75\n",
        "p_of_class_6_pix=p_of_class_6_pix/75.75\n",
        "p_of_class_7_pix=p_of_class_7_pix/75.75\n",
        "p_of_class_8_pix=p_of_class_8_pix/75.75\n",
        "\n",
        "print('percentage of class 0 pixels:', p_of_class_0_pix)\n",
        "print('percentage of class 1 pixels:', p_of_class_1_pix)\n",
        "print('percentage of class 2 pixels:', p_of_class_2_pix)\n",
        "print('percentage of class 3 pixels:', p_of_class_3_pix)\n",
        "print('percentage of class 4 pixels:', p_of_class_4_pix)\n",
        "print('percentage of class 5 pixels:', p_of_class_5_pix)\n",
        "print('percentage of class 6 pixels:', p_of_class_6_pix)\n",
        "print('percentage of class 7 pixels:', p_of_class_7_pix)\n",
        "print('percentage of class 8 pixels:', p_of_class_8_pix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBFQwn3-x631"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage.io\n",
        "\n",
        "# Load your DataFrame containing image and label file paths\n",
        "# train_file = pd.read_csv('your_train_file.csv')\n",
        "\n",
        "# List of class labels\n",
        "class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "# Initialize dictionary to store class pixel counts\n",
        "class_pixel_counts = {label: 0 for label in class_labels}\n",
        "\n",
        "# Iterate over masks and calculate pixel counts for each class\n",
        "for mask_path in train['component label file name']:\n",
        "    img = skimage.io.imread(mask_path)\n",
        "    for label in class_labels:\n",
        "        class_pixel_counts[label] += np.sum(img == label)\n",
        "\n",
        "# Calculate total number of pixels\n",
        "total_pixels = sum(class_pixel_counts.values())\n",
        "\n",
        "# Calculate class frequencies and class weights\n",
        "class_frequencies = {label: count / total_pixels for label, count in class_pixel_counts.items()}\n",
        "class_weights = {label: 1 / freq for label, freq in class_frequencies.items()}\n",
        "\n",
        "print('Class Frequencies:', class_frequencies)\n",
        "print('Class Weights:', class_weights)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IOWm2-h3uCsr",
        "dpMrEqANiUdy",
        "rSCuRgTOeeFk",
        "KC-HgQrKO8pE",
        "lbbqFYKuP7MN",
        "0vzIHanwJdAT"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}